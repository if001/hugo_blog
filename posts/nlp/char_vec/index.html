<!DOCTYPE html>
<html lang="ja">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no, maximum-scale=1" />
  
  <meta name="description" content="文章生成にchar-level lstmを使ってみる。英語ではうまくいっている例があるが日本語では難しい。これは、日本語は英語に比べ文字数が多く、ニューラルネットワークの次元数(パラメータ数)が増やす必要があるのが原因の1つだと思う。また、次元削減のため、日本語では文章を単語に区切り単語をベクトル化し、lstmで文章を生成する手法もあるが、単語に区切る時点でしゃべり言葉やネットの言葉ではうまく区切れないという問題がある。そこで、日本語の文字を画像として生成し、その画像をauto-encoderを用いてベクトル化することで、文字のベクトル化を行い、lstmに食わせるという手法を試して見ようと思う。
今回は、auto-encodeを用いた文字レベルのベクトル化までを行ってみようと思う。
コードはここ、https://github.com/if001/fifc.git
以下の3工程で行う。
 フォントファイルからフォント画像を生成 文字列とフォント画像をマッピング フォント画像から特徴量を生成  フォントファイルからフォント画像を生成 フォントファイルは、PILのImageFontのturetypeを使い読み込むことができる。">
  
  <meta property="og:title" content="文字をベクトル化する" />
<meta property="og:description" content="文章生成にchar-level lstmを使ってみる。英語ではうまくいっている例があるが日本語では難しい。これは、日本語は英語に比べ文字数が多く、ニューラルネットワークの次元数(パラメータ数)が増やす必要があるのが原因の1つだと思う。また、次元削減のため、日本語では文章を単語に区切り単語をベクトル化し、lstmで文章を生成する手法もあるが、単語に区切る時点でしゃべり言葉やネットの言葉ではうまく区切れないという問題がある。そこで、日本語の文字を画像として生成し、その画像をauto-encoderを用いてベクトル化することで、文字のベクトル化を行い、lstmに食わせるという手法を試して見ようと思う。
今回は、auto-encodeを用いた文字レベルのベクトル化までを行ってみようと思う。
コードはここ、https://github.com/if001/fifc.git
以下の3工程で行う。
 フォントファイルからフォント画像を生成 文字列とフォント画像をマッピング フォント画像から特徴量を生成  フォントファイルからフォント画像を生成 フォントファイルは、PILのImageFontのturetypeを使い読み込むことができる。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.if-blog.site/posts/nlp/char_vec/" />

<meta property="og:image" content="https://www.if-blog.site/images/logo/logo.jpeg" />
<meta property="article:modified_time" content="2019-09-24T15:31:42+09:00" />

  <meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://www.if-blog.site/images/logo/logo.jpeg"/>

<meta name="twitter:title" content="文字をベクトル化する"/>
<meta name="twitter:description" content="文章生成にchar-level lstmを使ってみる。英語ではうまくいっている例があるが日本語では難しい。これは、日本語は英語に比べ文字数が多く、ニューラルネットワークの次元数(パラメータ数)が増やす必要があるのが原因の1つだと思う。また、次元削減のため、日本語では文章を単語に区切り単語をベクトル化し、lstmで文章を生成する手法もあるが、単語に区切る時点でしゃべり言葉やネットの言葉ではうまく区切れないという問題がある。そこで、日本語の文字を画像として生成し、その画像をauto-encoderを用いてベクトル化することで、文字のベクトル化を行い、lstmに食わせるという手法を試して見ようと思う。
今回は、auto-encodeを用いた文字レベルのベクトル化までを行ってみようと思う。
コードはここ、https://github.com/if001/fifc.git
以下の3工程で行う。
 フォントファイルからフォント画像を生成 文字列とフォント画像をマッピング フォント画像から特徴量を生成  フォントファイルからフォント画像を生成 フォントファイルは、PILのImageFontのturetypeを使い読み込むことができる。"/>

  
  <title>
  
       文字をベクトル化する | アンドロイドは推理小説を書くか? 
  
  </title>

  <link href="https://use.fontawesome.com/releases/v5.6.1/css/all.css" rel="stylesheet">

  <link rel="canonical" href="https://www.if-blog.site/posts/nlp/char_vec/">

  
  

  
  <link href="https://www.if-blog.site/css/vendors-extensions/fontawesome/all.min.css" rel="stylesheet">

  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700|Ubuntu+Mono:400,400i,700,700i|Raleway:300,400,500,600">
  <link href="https://www.if-blog.site/css/font.css" rel="stylesheet"> 
    
  
  <link href="https://www.if-blog.site/css/vendors/bootstrap4/bootstrap.min.css" rel="stylesheet">
  <link href="https://www.if-blog.site/css/vendors-extensions/mdb/mdb.min.css" rel="stylesheet"> 
  <link href="https://www.if-blog.site/css/vendors/mdb/style.min.css" rel="stylesheet"> 
  <link href="https://www.if-blog.site/css/main.css" rel="stylesheet">


  
  <link rel="shortcut icon"
  
      href="https://www.if-blog.site/images/favicon/favicon1.jpeg"
  
  >


  
  

  <style type="text/css">
      @media (min-width: 800px) and (max-width: 850px) {
              .navbar:not(.top-nav-collapse) {
                  background: #1C2331!important;
              }
          }
  </style>


  
    
    <link rel="stylesheet" href="https://www.if-blog.site/js/vendors/katex/katex.min.css">
  
  

  
    
    <link rel="stylesheet" href="https://www.if-blog.site/css/vendors/highlight/github-gist.css">
  

    
    
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\[','\]']],
        processEscapes: true,
        processEnvironments: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
        TeX: { equationNumbers: { autoNumber: "AMS" },
             extensions: ["AMSmath.js", "AMSsymbols.js"] }
      }
    });
    </script>
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    

    
    <script data-ad-client="ca-pub-7303877370233278" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>

  <body class="bg-light" data-spy="scroll" data-target="#page-scrollspy" data-offset="90">
    
    
    
    
    
    


<nav class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar">
    <div class="container">

      
      <a class="navbar-brand" href="https://www.if-blog.site">
          
        <strong> </strong>
      </a>

      
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
        aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

      
      <div class="collapse navbar-collapse" id="navbarSupportedContent">

        
        <ul class="navbar-nav mr-auto ">
          <li class="nav-item ">
            <a class="nav-link" href="https://www.if-blog.site">アンドロイドは推理小説を書くか?</a>
          </li>
          
        </ul>

      </div>

    </div>
  </nav>
  

    

    
    
    
    

    
  
  <main class="post-main-wrapper">
    
    <div class="row">

      

      
      <div class="container pr-5">
      

        
        <div class="z-depth-1  post-wrapper white-bg single-post">

          <div class="post-header text-center" >
  <ul class="post-meta li-x">
    
    
  </ul>

  <div class="px-4 post-heading">文字をベクトル化する</div>

  <ul class="post-meta li-x mt-1">
    
    <li>2019-09-24</li>
    

    
    
    
    
  </ul>
  

</div>


	  <div class="row">
            <div class="mb-5">
              
<div class="li-x div-x post-meta">
  <li class="pr-0"><a href="https://www.if-blog.site/tags/"><i class="fas fa-tags"></i></a></li>
  <div class="tags-sm">
    
      <li><a href="https://www.if-blog.site/tags/nlp" role="button">nlp </a></li>
      
    
      <li><a href="https://www.if-blog.site/tags/neuralnet" role="button">neuralnet </a></li>
      
    
      <li><a href="https://www.if-blog.site/tags/python" role="button">python </a></li>
      
    
  </div>
</div>

            </div>	
	  </div>
	  
          <div class="post-content markdown">
            

<p>文章生成にchar-level lstmを使ってみる。英語ではうまくいっている例があるが日本語では難しい。これは、日本語は英語に比べ文字数が多く、ニューラルネットワークの次元数(パラメータ数)が増やす必要があるのが原因の1つだと思う。また、次元削減のため、日本語では文章を単語に区切り単語をベクトル化し、lstmで文章を生成する手法もあるが、単語に区切る時点でしゃべり言葉やネットの言葉ではうまく区切れないという問題がある。そこで、日本語の文字を画像として生成し、その画像をauto-encoderを用いてベクトル化することで、文字のベクトル化を行い、lstmに食わせるという手法を試して見ようと思う。<br />
今回は、auto-encodeを用いた文字レベルのベクトル化までを行ってみようと思う。<br />
コードはここ、<a href="https://github.com/if001/fifc.git" target="_blank">https://github.com/if001/fifc.git</a></p>

<p>以下の3工程で行う。</p>

<ul>
<li>フォントファイルからフォント画像を生成</li>
<li>文字列とフォント画像をマッピング</li>
<li>フォント画像から特徴量を生成</li>
</ul>

<h2 id="フォントファイルからフォント画像を生成">フォントファイルからフォント画像を生成</h2>

<p>フォントファイルは、PILのImageFontの<a href="https://pillow.readthedocs.io/en/3.0.x/reference/ImageFont.html#PIL.ImageFont.truetype" target="_blank">turetype</a>を使い読み込むことができる。<br />
フォントファイルとフォントのサイズを引数に与えることで、fontオブジェクトが生成できる。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">ImageFont</span>
<span class="n">font_size</span><span class="o">=</span><span class="mi">28</span>
<span class="n">font</span> <span class="o">=</span> <span class="n">ImageFont</span><span class="o">.</span><span class="n">truetype</span><span class="p">(</span><span class="n">font_file</span><span class="p">,</span> <span class="n">font_size</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;unic&#39;</span><span class="p">)</span></code></pre></div>
<p>読み込んだフォントは下記のように保存する。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">pict_height</span><span class="o">=</span><span class="mi">28</span>
<span class="n">pict_width</span><span class="o">=</span><span class="mi">28</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">pict_height</span><span class="p">,</span> <span class="n">pict_width</span><span class="p">),</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">))</span>
<span class="n">draw</span> <span class="o">=</span> <span class="n">ImageDraw</span><span class="o">.</span><span class="n">Draw</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">draw</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">yomi</span><span class="p">,</span> <span class="n">font</span><span class="o">=</span><span class="n">font</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="s1">&#39;#000000&#39;</span><span class="p">)</span>
<span class="n">image</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&#34;./font&#34;</span><span class="p">,</span> <span class="s1">&#39;PNG&#39;</span><span class="p">)</span></code></pre></div>
<pre><code>Image.new()
</code></pre>

<p>で空のイメージを生成し、</p>

<p>Drawオブジェクトに対しの<a href="https://pillow.readthedocs.io/en/3.0.x/reference/ImageDraw.html#PIL.ImageDraw.PIL.ImageDraw.Draw.text" target="_blank">text関数</a>を用いてフォントファイルを書き込む。</p>

<pre><code>draw.text(pos, yomi, font=font, fill='#000000')
</code></pre>

<p>引数は、上記のtext関数のリンクを参照。</p>

<p>保存するファイル名は、以下のように文字を16進数変換したものを使う。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">yomi</span><span class="o">=</span><span class="s2">&#34;歩&#34;</span>
<span class="n">bytes_yomi</span> <span class="o">=</span> <span class="n">yomi</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&#34;UTF-8&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">hex</span><span class="p">()</span>
<span class="o">&gt;&gt;</span> <span class="s1">&#39;e6ada9&#39;</span></code></pre></div>
<h2 id="文字列とフォント画像をマッピング">文字列とフォント画像をマッピング</h2>

<p>ファイル名を読み仮名を16進数変換し保存しているので、文字から毎回画像ファイルを読み込んでも良いが、高速に呼び出せるように、1文字と画像をファイルとkvsを使ってマッピングしておく。<br />
kvsにはplyvelを使う。以下のようにインスタンス化する。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">plyvel</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">plyvel</span><span class="o">.</span><span class="n">DB</span><span class="p">(</span><span class="n">db_path</span><span class="p">,</span> <span class="n">create_if_missing</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></div>
<p>以下のように、保存と取り出しを行う。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">db</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="c1"># 保存</span>
<span class="n">db</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="c1"># 取り出す</span></code></pre></div>
<h2 id="フォント画像から特徴量を生成">フォント画像から特徴量を生成</h2>

<p>auto-encoderを使って、保存した画像から特徴量を抽出する。<br />
モデルの構造はkerasの公式ブログを参考にし、以下の構造とした。</p>

<figure>
    <img src="../../images/char_vec/auto-encoder-img.png" width="200"/> 
</figure>


<p>各層の次元は以下のようにした。</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">font_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">input_img</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">font_size</span><span class="p">,</span> <span class="n">font_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">input_img</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
           <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;encoder&#34;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;decoder&#34;</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">UpSampling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">UpSampling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">UpSampling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>

<span class="n">decoded</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">autoencoder</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">input_img</span><span class="p">,</span> <span class="n">decoded</span><span class="p">)</span>
<span class="n">autoencoder</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span></code></pre></div>
<h3 id="学習">学習</h3>

<p>損失関数と最適化関数はそれぞれ、mean_squared_errorとadamを用いた。</p>

<p>教師データとバリデーションデータはそれぞれ、66918個、16730個とした。また、バッチサイズは128とした。<br />
学習は、kerasのearlystoppingを使いval_lossが減少がなくなるまで行った。</p>

<h3 id="結果">結果</h3>

<figure>
    <img src="../../images/char_vec/training_log.png" width="500"/> 
</figure>


<p>最中的なスコア</p>

<pre><code>epoch :4  
acc :0.591411  
loss :0.046486  
val_acc :0.529843  
val_loss:0.073542  
</code></pre>

<p>だいぶ早めに学習が打ち切られているのがわかる。<br />
2epoch目くらいからほとんどlossもaccも変化しなくなっている。次元数や層の数が少なくパラメタが足りないのか???</p>

<p>一応デコードされた文字を確認しておく。</p>

<figure>
    <img src="../../images/char_vec/decoded_char.png" width="100"/> 
</figure>


<p>左が教師データ、右がdecodeされた文字となる。auto-encoderなのでぼやけているのはしょうがないが割と綺麗にデコードできている。ただし、画数の多い文字となるとやはりぼやけて元の文字がわからない。この辺は、モデルや学習のパラメタを調整することでも少し改善されると思う。</p>

<p>生成された特徴量も確認しておく。<br />
以下に、&rsquo;寂&rsquo;, &lsquo;,&rsquo;, &lsquo;ッ&rsquo;, &lsquo;鏡&rsquo;, &lsquo;奸&rsquo;, &lsquo;Ｐ&rsquo;, &lsquo;跳&rsquo;, &lsquo;・&rsquo;, &lsquo;“&rsquo;, &lsquo;ょ&rsquo;の記号を含む10文字を与えた際の特徴量を図示する。
特徴量は、1文字あたり(4,4,8)次元となるので、4×4の画像を8枚横に並べたものを表示している。</p>

<figure>
    <img src="../../images/char_vec/hidden_dim.png" width="600"/> 
</figure>


<p>図をみると、文字ごとの偏りはなく学習できているように見える。</p>

<p>lossは0.04とある程度小さい値となったが、accは0.6とそこまで高い値とはならなかった。改善のため何をすれば良いかの指標がいまいちわからん。損失関数と最適化関数は良さそうなので、とりあえず、層の数やunit数、学習率などのパラメタや教師データを増やすなど試してみようと思う。随時更新していく。</p>

          </div>

          
          <div class="row">
            <div class="col-md-8">
            
              <div class="mb-5">
                
<div class="li-x div-x post-meta">
  <li class="pr-0"><a href="https://www.if-blog.site/tags/"><i class="fas fa-tags"></i></a></li>
  <div class="tags-sm">
    
      <li><a href="https://www.if-blog.site/tags/nlp" role="button">nlp </a></li>
      
    
      <li><a href="https://www.if-blog.site/tags/neuralnet" role="button">neuralnet </a></li>
      
    
      <li><a href="https://www.if-blog.site/tags/python" role="button">python </a></li>
      
    
  </div>
</div>

              </div>
            
            </div>
            
          </div>
          

	  
          <div class="row pt-3">
	    

<h3>See Also</h3>
<ul>
    
    <li><a href="/posts/python-get-extn/">pythonで拡張子を取得する</a></li>
    
    <li><a href="/posts/falcon/falcon-img-upload/">falconでアップロードサーバーを作る</a></li>
    
    <li><a href="/posts/neuralnet/pepar_summary/">Deeplearningまわりの最新論文を浅く広くみてまわる</a></li>
    
    <li><a href="/posts/python/colaboratory_google_drive_mount/">Google ColaboratoryでGoogle driveをマウントする</a></li>
    
    <li><a href="/posts/nlp/seqgan-paper/">SeqGANの論文を読む</a></li>
    
</ul>


	  </div>

	  
          
          
          
          
          
          
          
          
          
          
          
          
            
          
          
          
          
          
          
          
          
          
          
          
          
	  
<div id="share-buttons">
  <ul style="list-style: none;">
    
    <li style="display: inline; margin:5px;">
      <a href="https://twitter.com/share" class="twitter-share-button">Tweet</a>
      <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
    </li>
    
    
    
    <li style="display: inline; margin:5px;">
      <a href="http://b.hatena.ne.jp/entry/https://www.if-blog.site/posts/nlp/char_vec//" class="hatena-bookmark-button" data-hatena-bookmark-title="文字をベクトル化する" data-hatena-bookmark-layout="standard-balloon" data-hatena-bookmark-lang="ja" title="このエントリーをはてなブックマークに追加"><img src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" /></a><script type="text/javascript" src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
    </li>
    
    
    
    
    <li style="display: inline; margin:5px;">
	<a data-pocket-label="pocket" data-pocket-count="horizontal" class="pocket-btn" data-lang="en"></a>
	<script type="text/javascript">!function(d,i){if(!d.getElementById(i)){var j=d.createElement("script");j.id=i;j.src="https://widgets.getpocket.com/v1/j/btn.js?v=1";var w=d.getElementById(i);d.body.appendChild(j);}}(document,"pocket-btn-js");</script>
    </li>
    

  </ul>
</div>


        </div>
        

      </div>
      

      

      
    </div>
    


  </main>
  

    
    
    

<footer class="page-footer text-center font-small mt-4 wow fadeIn">


  
  <div class="pb-2 mt-5 pt-5">
    
    

    

    

    

    

    


    

    

    

  </div>
  

  
  <div class="copyright py-4">
    
    <span>  2016 - 2019 &copy; | Theme <a href='https://github.com/orianna-zzo/AllinOne' target="_blank">AllinOne</a> by <a href='https://github.com/orianna-zzo' target="_blank">Orianna</a>  </span>
  </div>
  

</footer>


    






<script type="text/javascript" src="https://www.if-blog.site/js/vendors/jquery/jquery-3.3.1.min.js"></script>
<script type="text/javascript" src="https://www.if-blog.site/js/vendors/jquery/jquery.smooth-scroll.min.js"></script>



<script type="text/javascript" src="https://www.if-blog.site/js/vendors/popper.min.js"></script>
<script type="text/javascript" src="https://www.if-blog.site/js/vendors/holder.min.js"></script>
<script type="text/javascript" src="https://www.if-blog.site/js/vendors-extensions/bootstrap4/bootstrap.js" ></script>

<script type="text/javascript" src="https://www.if-blog.site/js/vendors/mdb/mdb.min.js"></script>

<script type="text/javascript" src="https://www.if-blog.site/js/main.js"></script>



  
  <script src="https://www.if-blog.site/js/vendors/highlight.pack.js"> </script>
  <script>hljs.initHighlightingOnLoad();</script>




 
  <script src="https://www.if-blog.site/js/vendors/katex/katex.min.js"> </script>
  <script src="https://www.if-blog.site/js/vendors/katex/contrib/auto-render.min.js"></script>

  <script>
      document.addEventListener("DOMContentLoaded", function () {
          renderMathInElement(document.body);
      });
  </script>






<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-127416809-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



<script type="text/javascript">
  
  new WOW().init();
</script>




  </body>
</html>

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nlp on アンドロイドは推理小説を描くか?</title>
    <link>https://if001.github.io/tags/nlp/</link>
    <description>Recent content in Nlp on アンドロイドは推理小説を描くか?</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="/tags/nlp/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>SeqGANの論文を読む</title>
      <link>https://if001.github.io/post/nlp/seqgan-paper/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://if001.github.io/post/nlp/seqgan-paper/</guid>
      <description>SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient
https://arxiv.org/pdf/1609.05473.pdf
SeqGANの論文を読んだのでまとめておきます。実装を行おうと思って読んだので手法をメインに読みます。 結果などは余力があれば加筆します。
はじめに 文章生成では、LSTMcellを使ったRNNが優れたパフォーマンスを行う。一般的な学習法は対数尤度を最大化する方法だが、次のような問題点がある。
 exposure bias(予測時には、自分の出力から次の語を予測することによるbias) BLEUを使っても良いけど、詩やchatbotだと難しい  これらの問題に対して、General adversarial net(GAN)が有効そうである。ただし2つの問題がある。
 GANは連続データを生成するように設計されており、sequenceなどの離散データを直接生成するのは難しい。生成モデルGのパラメータの更新に識別モデルDの勾配を用いているが、微小な勾配により更新された生成モデルGに対応する出力値が離散のため存在しない可能性があるためである。 GANは、生成された文全体に対して、score/lossのみを与えることができる。部分的に生成されたsequenceには、文全体としての現在と将来のscoreのバランスをどのようにうまく取れば良いかが自明でない。  そこで、生成モデルに強化学習を用いたGANであるSeqGANを提案する。
Sequence Generative Adversarial Nets 生成モデル$G_ \theta $はパラメータを$\theta$として、$Y_ {1:T} = (y_ 1, y_ 2 , y_ T)$,$y_ t \in \mathcal Y$ を生成するために学習する。ここで、$\mathcal Y$はvocabularyを表す。
学習には、強化学習を用いる。時刻$t$において、状態$s$は現在の単語列$(y_ {1},y_ {2}, \ldots ,y_ {t-1})$を表し、行動$a$により次の単語$y_ t$を選択する。このため、方策モデル$G_ {\theta} (y_ {t}|Y_ {1:t-1})$ は確率的である。一方、行動を選択したあとでは、状態遷移は決定的である。つまり、もし現在の状態が$s=Y_ {1:t-1}$で行動が$a=y_ {t}$ならば、次の状態$s&amp;rsquo;=Y_ {1:t}$に対して、$\delta^a_ {s,s&amp;rsquo;}=1$である。そうでないなら、次の状態$s&amp;rdquo;$に対して$\delta^a_ {s,s&amp;rdquo;}=0$である。
加えて、パラメーター$\phi$を持つ識別モデル$D_ \phi$は、生成モデル$G_ \theta$を学習しながら正解を識別する。識別モデル$D_ \phi$は、本物の文章かどうかを確率的に識別する。</description>
    </item>
    
    <item>
      <title>ニューラルネットワークを用いた対話モデルのための多様性を促進する目的関数</title>
      <link>https://if001.github.io/post/nlp/diversity_neural_conversation_model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://if001.github.io/post/nlp/diversity_neural_conversation_model/</guid>
      <description>Qiitaに投稿した記事、kerasでHREDを構築してみるの記事で、こちらの論文が参考になるとのコメント頂いて、読んで見たので簡単にまとめました。
A Diversity-Promoting Objective Function for Neural Conversation Models https://arxiv.org/abs/1510.03055
会話タスクにおける、入力文章(メッセージ)とそれに対する応答に多様性をもたせる手法を提案した論文です。 モデル周りをメインにそれ以外は軽く流し読みしているので、悪しからず。
はじめに sequence to sequece(seq2seq)などの対話モデルでは、多様で文法的な応答が求められる。このモデルでは、入力される文章と出力される文章の対応のみを考慮しているため、I&amp;rsquo;m OKやI&amp;rsquo;dont knowのような高頻度フレーズを生成しがちである。したがって、メッセージに関する応答の依存性だけでなく、応答とメッセージの関係性についても考慮すべきである。
そこで、私たちは、Maximum Mutual Information（MMI）を目的関数とする対話モデルを提案する。私たちは、MMIを使用することで、多様で興味深い文章を生成することを示します。
MMIモデル seq2seqモデルの標準的な目的関数は以下のように表される。
$$\hat{T} = argmax_T{\log p(T|S)}$$
$N$は単語数を表し、入力文章(メッセージ)$S$とそれに対する応答$T$は以下のように表される。 $S = {s_1, s2, &amp;hellip;, s{N_s} }$ $T = {t_1, t2, &amp;hellip;, t{N_t}, EOS}$
seq2seqモデルの目的関数を以下のように修正する。
$$\hat{T} = argmax_T {\log p(T|S) - \log p(T)}$$
このとき、argmaxの中身は、以下のように式変形から、相互情報量(wikipedia) を表していることがわかる。
$${\log p(T|S) - \log p(T)} = \frac{\log p(S,T)}{\log p(S) \log p(T)}$$
したがって、この式は、相互情報量を最大化(MMI)する応答を出力することとなる。
また、$\log p(T)$は、seq2seqの標準的な目的関数に対するペナルティ項とみなすことができる。メッセージに対するありふれた応答に対してペナルティを与えることで、応答の多様性を保つことを期待している。
このペナルティー項を調節できるように、(2)式に対して、パラメタ$\lambda$を追加する。 これを、MMI-antiLMと呼ぶ。 $$\hat{T} = argmax_T {\log p(T|S) - \lambda \log p(T)} \tag{1}$$</description>
    </item>
    
    <item>
      <title>自然言語処理シリーズの構文解析を読む（概要）</title>
      <link>https://if001.github.io/post/nlp/nlp-parse-overview-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://if001.github.io/post/nlp/nlp-parse-overview-1/</guid>
      <description>はじめに 自然言語処理シリーズの構文解析を読んでいきます。   全体の概要把握:1時間 中身の細かいとこ：3時間 という感じで読み進めて行こうと思います。
概要 構文解析を用いることで、単語の並びの背後にある文法的な構造を明らかにすることができる。構文解析を学ぶことで、自然言語処理で用いられる様々な先人の知恵を学習できる。
この本では以下のような構成となっている。
 1章、はじめに 2章、品詞タグ付けのための手法と、機械学習の基礎的な事項について 3章、句構造解析について 4章、依存構造解析 5章、文法理論、深い構文解析 6章、構文解析の応用例 7章、構文解析ツールの紹介 8章、モデルやアルゴリズムの学習用・評価用データに用いられるツリーバンクの紹介  以下、各章の概要まとめです。
2章：品詞解析と機械学習 品詞解析のためのさまざまな技術の解説し、その基盤となる機械学習の考え方と代表的なモデルを紹介する。
品詞タグ付け：与えられた文章の各単語の品詞を判定し、品詞情報を付与する処理 品詞タガー：品詞タグ付けを行うプログラム ルールベースの手法：shoudの後には動詞がくると決めうちでタグ付けをする手法 素性: 品詞判定の手がかりとして利用する情報
隠れマルコフモデル 機械学習に基づく品詞タグ付け手法の中で基本的なもの。 単純な計算では、文長に対し計算量が指数関数的に増加する問題がある。
Viterbiアルゴリズム 計算量増加の問題を解決。動的計画法の1種。 アンダーフローの問題がある、この問題に対し、対数をとっても良いが計算が遅くなるというデメリットもある。
最大エントロピーモデル 最大エントロピーモデルは、品詞判定に役立つ手がかりを素性として利用し予測できるアルゴリズムの一種。品詞の前後のつながりを考慮せずに予測するというモデル。 計算コストは少ないが、素性を柔軟に設計できないため精度が低いという問題点がある。 自然言語処理では、実装が簡単なことからSGDがよく用いられる。学習データの数が多い場合には、短時間で最適化を行うことができる。
最大エントロピーマルコフモデル 最大エントロピーモデルに、品詞のつながりを考慮させ正確な予測を行うことできるように改良されたモデル。 先行する単語の品詞に関数情報を素性として利用するできるが、最初にタグ付けを間違えると、その誤りによって別の誤りが引き起こされてしまう問題がある。
条件付き確率場(CRF) 各単語の品詞を個別に予測するのではなく、文全体の品詞列全体を一度に予測しようとするアプローチに基づく代表的な確率モデル。
構造化パーセプトロン CRFでは、登場する品詞列すべてに対し確率を求めるが、もっとも正解である確率の高い品詞列さえ得られれば良いという状況もある。そのような状況では、構造化パーセプトロンが役にたつ。動的計画法を用いて品詞タグ付けを行う。
ビーム探索 構造化パーセプトロンでは動的計画法を用いて品詞タグ付けを行ったが、素性が局所的な場合には、動的計画法が使えない。そこで、非局所的な様々な素性を利用するためによく用いられるのがビーム探索である。似たような手法として、Max Violationがある。
生コーパスを利用した学習 これまでの学習は、コーパスを前提にしたものだった。しかしコーパスの構築には膨大な時間がかかる。与えられた文章のみで学習する手法を、半教師あり学習と呼ぶ。
自己学習 生コーパスを用いる学習に自己学習と呼ばれる方法がある。 これは、CRFや構造化パーセプトロンでは精度向上に効果がないが、隠れマルコフモデルのような生成モデルでは大きな精度向上を得ることができる。これは、生成モデルの場合、EMアルゴリズムの1ステップに対応しているからである。隠れマルコフモデルで自己学習を行う場合、Baum-Welchアルゴリズムを用いる。
3章：句構造解析 構文解析の表現方法の1つである句構造と、それに基づく構文解析の手法について説明する。
句構造 文中の句同士の包含関係を階層的にまとめあげることで、その構造を明らかにする。 適切な句構造を得るための問題を2つに分けると、与えられた文に対して文法上可能な全ての句構造を計算することと、それらの中から最も適切な句構造を選択することとなる。
文脈自由文法 文の句構造を表現するための、最も基本的な文法の一つ。 文脈自由文法のためのボトムアップな構文解析手法の一つであるCKY法と、任意の文脈自由文法を用いてトップダウンに構文解析を行うことが可能なEarly法がある。
確率文脈自由文法(PCFG) 句構造を列挙した上で、最も確からしい句構造を選択する枠組みの1つ
確率文脈自由文法(PCFG)の拡張 PCFGを拡張した、Collins Parserの手法について解説 生成的な確率モデルを注意深く設計することで、正しい構文木にたいして大きな確率がわりあてられるようにする。
識別モデルによる際順位付け 正しい構文木とそうでない構文木を区別する特徴はいくつかあるが、Collins Parserでは限られたものしか考慮することができない。</description>
    </item>
    
  </channel>
</rss>

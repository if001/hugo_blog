<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on アンドロイドは推理小説を描くか?</title>
    <link>http://www.if-blog.site/post/</link>
    <description>Recent content in Posts on アンドロイドは推理小説を描くか?</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="/post/" rel="self" type="application/rss+xml" />
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/falcon/falcon-image-upload/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/falcon/falcon-image-upload/</guid>
      <description>title=falconでアップロードサーバーを作る slug=falcon-img-upload tags=[Hugo,python, falcon]
はじめに 現在、サーバー上にHugoとHugoが生成した静的ファイルを置いてブログを公開している。 静的ファイルの生成とmdファイルや画像ファイルのアップロードのためfalconを使ってapiサーバーを作った。 falconをつかったのは、flaskやbottleは使ったことあったので、使ったことないものをということで。
クライアント クライアントにはpythonのrequestsを使います。
fileにタプルでファイル名を明示的に渡せる。 postの引数にfilesで渡すと、contents-typeもよしなにしてくれるんですね。
image_name = &amp;quot;test.png&amp;quot; with open(image_file_path, &amp;quot;rb&amp;quot;) as image: files = {&#39;file&#39;: (image_name, image)} response = requests.post(url, files=files) print(response.text)  サーバー falconはコンテナ上で動かします。ファイルアップロードのリクエストを受けると、 サーバー上のストレージに画像を保存します。
なんかできないと思ってたら、middlewareにMultipartMiddlewareを指定しないとだめだった。
fileは次のようにrequestから取得できる
image = req.get_param(&#39;file&#39;) raw = image.file.read()  ファイル名は次のように取得
image_name = image.filename  実際は、corsとかあるがそれを省いた、アップロードだけの全体は以下のようになる。
from falcon_multipart.middleware import MultipartMiddleware import falcon import json class UploadImage(object): def on_post(self, req, resp): image = req.get_param(&#39;file&#39;) raw = image.file.read() image_name = image.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/falcon/falcon-tips/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/falcon/falcon-tips/</guid>
      <description>title=falconを使ってみた slug=falcon-tips tags=[python, falcon]
はじめに Hugoをおいているwebサーバーに画像や、mdファイルをアップロードするためのapiサーバーとしてfalconを使ってみた。ORMなど必要なく、簡単なアップロードができれば良いということで、軽量さとシンプルさが特徴のfalconを使う。
簡単なtipsをメモしておく。
シンプルな例 falconの公式に乗っているように、シンプルな例は次のようになる。
# sample.py import falcon class QuoteResource: def on_get(self, req, resp): &amp;quot;&amp;quot;&amp;quot;Handles GET requests&amp;quot;&amp;quot;&amp;quot; quote = { &#39;quote&#39;: ( &amp;quot;I&#39;ve always been more interested in &amp;quot; &amp;quot;the future than in the past.&amp;quot; ), &#39;author&#39;: &#39;Grace Hopper&#39; } resp.media = quote api = falcon.API() api.add_route(&#39;/quote&#39;, QuoteResource())  処理シーケンス falconにはmiddlewareの他に、hooksというものが使える。 hooksを含めた処理シーケンスは次のようになる。
Middleware&#39;s process_request Middleware&#39;s process_resource Hook&#39;s before Resource&#39;s on_**** Hook&#39;s after Middleware&#39;s process_response  引用：https://qiita.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/hugo/hugo-add-site-description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/hugo/hugo-add-site-description/</guid>
      <description>title=Hugoの記事にdescriptionを追加する slug=hugo-add-site-description tags=[Hugo]
Hugoで書いた記事が検索で引っかからないなと思っていたら、descriptionタグが設定されていませんでした。 これでは検索に引っかからないのでdescriptionタグをつけましょう!
html側で次のように書くと、markdownに書いたdescriptionが参照できます。
{{ .Description }}  markdown側では、ヘッダーに次のように記述します。
description=&amp;quot;hogehoge&amp;quot;  これまで書いた記事全てに、descriptionをつけていくのは面倒ですね。
次のようにサイトサマリーを参照することも可能です
{{ .Summary }}  ただし、デフォルトでサマリーが大きくなりすぎるので、config.tomlに次のような記述を追加します。
hasCJKLanguage = true  こうすることでサマリーがいい感じのサイズになります。
参考：https://blog.awm.jp/2016/01/02/hugo/
最終的に、header.htmlなどに次のように記述しておけば、descriptionを書いておくとそちらが使われるようになります。
{{ if .Description }} &amp;lt;meta name=&amp;quot;description&amp;quot; content=&amp;quot;{{ .Description }}&amp;quot;&amp;gt; {{ else }} &amp;lt;meta name=&amp;quot;description&amp;quot; content=&amp;quot;{{ .Summary }}&amp;quot;&amp;gt; {{ end }}  サイトのディスクリプションと記事のディスクリプションを分ける(追記) {{ if .IsHome }}でトップページかどうか判定できるので、トップページならば、configのディスクリプションを使い、記事内ならば記事に設定してあるディスクリプションを使う。
html側は次のように記述する。
{{ if .IsHome }} {{ with .Site.Params.description }} &amp;lt;meta name=&amp;quot;description&amp;quot; content=&amp;quot;{{ . }}&amp;quot;&amp;gt; {{ end }} {{ end }} {{ if .</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/hugo/hugo-first/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/hugo/hugo-first/</guid>
      <description>title=最初の記事です slug=first-article tags=[test] これまでQiitaに技術記事を投稿してましたが、Qiitaに投稿するまでもない備忘録などを管理しようと作ってみました。
wordpressとかはてぶろなど色々探してみましたが、せっかくなので自分で作ろうということで、Hugoを使って作ってみました。
Hugoを使った備忘録はいずれ。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/hugo/hugo-ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/hugo/hugo-ga/</guid>
      <description>title=Hugoにgoogle analyticsを導入する slug=hugo-ga tags=[google analytics,Hugo] description= Hugoにgoogle analytics(ga)を導入しようと思ったら意外と簡単だった。
まず、gaアカウントを作成。
config.tomlに
googleAnalytics = &amp;quot;{ga tracking ID}&amp;quot;  を設定するだけ。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/hugo/hugo-href-to-target-blank/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/hugo/hugo-href-to-target-blank/</guid>
      <description>title=Hugoでリンクを新しいウィンドウで開く slug=hugo-href-to-target-blank tags=[Hugo]
リンクは新しいウィンドウで開いて欲しい派なんだけど、Hugoではデフォルトで通常のリンクの開きかた(?)をする。
hrefではtarget=&#39;_blank&#39;を指定すれば良いのだが、markdownでどうすれば良いのか調べた。 Hugoでは次のようにconfig.tomlするといける。
[blackfriday] hrefTargetBlank = true  簡単！
参考：
 https://gohugo.io/getting-started/configuration/ https://www.meganii.com/blog/2017/02/25/hugo-markdown-href-target-blank/  </description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/hugo/hugo-start-article/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/hugo/hugo-start-article/</guid>
      <description>title=Hugoでブログを作る slug=hugo-start-article tags=[Hugo]
はじめに Hugoとは、go言語で書かれた、静的なwebサイトをbuildingするためのframeworkです。 Hugoを使ってブログを作ってみたので構築方法を簡単にまとめておきます。
サイトの作成 インストール brew install hugo  テンプレートの作成 hugo new site hugo-test  これで、次のようにテンプレートが作成されます。
$ ls hugo-test/ archetypes/ config.toml content/ data/ layouts/ static/ themes/  テーマの適応 https://themes.gohugo.io/ ここからテーマを探す。
例として、https://themes.gohugo.io/hugo-theme-learn/ を使います。
$ cd hugo-test/themes $ git clone https://github.com/matcornic/hugo-theme-learn.git  テーマを適応させるために、config.tomlにthemeを記述します。
theme = &amp;quot;hugo-theme-learn&amp;quot;  サーバーの起動 $ hugo server -D -t hugo-theme-learn  オプションDでDraftフラグのついた記事の確認、オプションtでテーマの適応です。 cloneしてきたtheme内の、layoutとstaticなどを、作成したテンプレート内のlayout、staticに移動しておくと、templateのマイナーチェンジが行えます。
デフォルトでhttp://localhost:1313/で起動するのでアクセスしてみる。
記事の追加 記事の作成
$ hugo new post/test.md hugo_test/content/post/test.md created  以下のようなmarkdownファイルが作成される</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/hugo/hugo-test-article/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/hugo/hugo-test-article/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/hugo/hugo_on_image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/hugo/hugo_on_image/</guid>
      <description>title=Hugoの記事に画像を載せる slug=hugo_on_image tags=[Hugo] Hugoに画像を載せるときは、shortcodesを使うと良いらしい。
画像の場合は、static/media以下に画像ファイルが置いてある状態で、次のように書く。
\{{&amp;lt; figure src=&amp;quot;/media/spf13.jpg&amp;quot; title=&amp;quot;Steve Francia&amp;quot; width=&amp;quot;320&amp;quot; height=&amp;quot;640&amp;quot; &amp;gt;}}  画像のサイズも指定可能。
ここでは、shortcodesをエスケープさせるために、/*を使っている。
{{&amp;lt; code &amp;gt;}}  すると、次のようなHTMLが出力される。
&amp;lt;figure&amp;gt; &amp;lt;img src=&amp;quot;/media/spf13.jpg&amp;quot; /&amp;gt; &amp;lt;figcaption&amp;gt; &amp;lt;h4&amp;gt;Steve Francia&amp;lt;/h4&amp;gt; &amp;lt;/figcaption&amp;gt; &amp;lt;/figure&amp;gt;  </description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/hugo/katex-introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/hugo/katex-introduction/</guid>
      <description>title=KaTeXを使ってみる slug=katex-introduction tags=[katex]
これまでMathJaxを使っていたが、描画が遅いということもあり、$\KaTeX$を使ってみることにしました。 KaTeX:https://katex.org/
以下を加えるだけでおk
&amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.css&amp;quot; /&amp;gt; &amp;lt;script src=&amp;quot;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script src=&amp;quot;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script&amp;gt;$(document).ready(function(){renderMathInElement(document.body,{delimiters: [{left: &amp;quot;[[&amp;quot;, right: &amp;quot;]]&amp;quot;, display: true},{left: &amp;quot;$&amp;quot;, right: &amp;quot;$&amp;quot;, display: false}]})});&amp;lt;/script&amp;gt;  MathJaxで表示していた数式も無事表示されてとりあえず問題なしです。 実際に入れてみた感じやっぱり早い。
参考 KaTeXによる数式の表示:https://sekika.github.io/2017/05/01/katex-equation/ KaTeXを導入しました:http://nshi.jp/contents/other/katex/ KaTeXのデモ:http://sixthform.info/katex/examples/demo.html</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/neuralnet/combine_model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/neuralnet/combine_model/</guid>
      <description>title=kerasでモデルを結合する slug=combine_model tags=[keras,neuralnet] autoencoderなどを作っていると、保存や推論を行う上での再利用性を考え、encoderとdecoderは分けてModelを作りたいことがある。
autoencoderの学習の際には、作成したencoderのModelとdecoderのModelを結合する。
Modelの結合は前はできなかった気がするが、できるようになっていたのでメモ。
Kerasのバージョンは、2.1.1
まずは、シンプルなモデルを2つ作る。input→model1→model2→outputを作る。
def model1(): layer_input = Input(shape=(None, 10)) layer_output = Dense(10)(layer_input) model = Model(layer_input, layer_output) model.summary() return model def model2(): layer_input = Input(shape=(None, 10)) layer_output = Dense(10)(layer_input) model = Model(layer_input, layer_output) model.summary() return model  まず、model1へのインプットを作る。model1のアウトプットをmodel2のインプットにし、Modelのインスタンスを作る。
m1 = model1() m2 = model2() inp = Input(shape=(None, 10)) model1_output = m1(inp) out = m2(model1_output) model = Model(inp, out) model.summary()  すると、こんな感じでモデルが結合できたのが確認できる。
Using TensorFlow backend. _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) (None, None, 10) 0 _________________________________________________________________ dense_1 (Dense) (None, None, 10) 110 ================================================================= Total params: 110 Trainable params: 110 Non-trainable params: 0 _________________________________________________________________ _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) (None, None, 10) 0 _________________________________________________________________ dense_2 (Dense) (None, None, 10) 110 ================================================================= Total params: 110 Trainable params: 110 Non-trainable params: 0 _________________________________________________________________ _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_3 (InputLayer) (None, None, 10) 0 _________________________________________________________________ model_1 (Model) (None, None, 10) 110 _________________________________________________________________ model_2 (Model) (None, None, 10) 110 ================================================================= Total params: 220 Trainable params: 220 Non-trainable params: 0 _________________________________________________________________  コード全体はこんな感じ。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/neuralnet/pepar_summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/neuralnet/pepar_summary/</guid>
      <description>title=Deeplearningまわりの最新論文を浅く広くみてまわる slug=pepar_summary tags=[neuralnet]
最新論文の情報を広く浅く集めたい場合の巡回するサイトたちをまとめておきます。
おすすめがあれば教えてください。
Google Scholar: https://scholar.google.com/schhp?hl=ja
研究者やキーワードが決まっていると探しやすい。ただ、ザッピングには向かない。
いろいろ論文の検索エンジン使ってたけど、結局これが残った。texの引用が楽
arXiv arXiv https://arxiv.org/
トップページは慣れないとちょっと見づらい。有名な研究者で検索したものや分野で絞り込んだものをチェックするのが使いやすそう。
arXivTimes https://medium.com/@arxivtimes
日本語、arXivのまとめ系、ツイッター
論文まとめてくれてるGitHub https://github.com/dennybritz/deeplearning-papernotes
arXivのまとめ。古いものは2011年から、新しいものは2018まで更新がある。
企業の論文 DeepMind https://deepmind.com/research/publications/
Microsoft Research Publications http://research.microsoft.com/apps/catalog/default.aspx?t=publications&amp;amp;ra=47200
Google Research Publications http://research.google.com/pubs/ArtificialIntelligenceandMachineLearning.html
Yahoo! Labs http://labs.yahoo.com/publication/?area=machine-learning</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/nlp/diversity_neural_conversation_model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/nlp/diversity_neural_conversation_model/</guid>
      <description>title=ニューラルネットワークを用いた対話モデルのための多様性を促進する目的関数 slug=diversity_neural_conversation_model tags=[Deeplearning, seq2seq, NLP,論文] Qiitaに投稿した記事、kerasでHREDを構築してみるの記事で、こちらの論文が参考になるとのコメント頂いて、読んで見たので簡単にまとめました。
A Diversity-Promoting Objective Function for Neural Conversation Models https://arxiv.org/abs/1510.03055
会話タスクにおける、入力文章(メッセージ)とそれに対する応答に多様性をもたせる手法を提案した論文です。 モデル周りをメインにそれ以外は軽く流し読みしているので、悪しからず。
はじめに sequence to sequece(seq2seq)などの対話モデルでは、多様で文法的な応答が求められる。このモデルでは、入力される文章と出力される文章の対応のみを考慮しているため、I&amp;rsquo;m OKやI&amp;rsquo;dont knowのような高頻度フレーズを生成しがちである。したがって、メッセージに関する応答の依存性だけでなく、応答とメッセージの関係性についても考慮すべきである。
そこで、私たちは、Maximum Mutual Information（MMI）を目的関数とする対話モデルを提案する。私たちは、MMIを使用することで、多様で興味深い文章を生成することを示します。
MMIモデル seq2seqモデルの標準的な目的関数は以下のように表される。
$$\hat{T} = argmax_T{\log p(T|S)}$$
$N$は単語数を表し、入力文章(メッセージ)$S$とそれに対する応答$T$は以下のように表される。 $S = {s_1, s2, &amp;hellip;, s{N_s} }$ $T = {t_1, t2, &amp;hellip;, t{N_t}, EOS}$
seq2seqモデルの目的関数を以下のように修正する。
$$\hat{T} = argmax_T {\log p(T|S) - \log p(T)}$$
このとき、argmaxの中身は、以下のように式変形から、相互情報量(wikipedia) を表していることがわかる。
$${\log p(T|S) - \log p(T)} = \frac{\log p(S,T)}{\log p(S) \log p(T)}$$</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/nlp/nlp_parse_overview-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/nlp/nlp_parse_overview-1/</guid>
      <description>nlp_parse_overview-1.html   perl: warning: Setting locale failed. perl: warning: Please check that your locale settings: LC_ALL = (unset), LC_CTYPE = &#34;UTF-8&#34;, LANG = &#34;en_JP.UTF-8&#34; are supported and installed on your system. perl: warning: Falling back to the standard locale (&#34;C&#34;). title=自然言語処理シリーズの構文解析を読む（概要） slug=nlp-parse-overview-1 tags=[nlp,構文解析]
はじめに 自然言語処理シリーズの構文解析を読んでいきます。   全体の概要把握:1時間 中身の細かいとこ：3時間 という感じで読み進めて行こうと思います。
概要 構文解析を用いることで、単語の並びの背後にある文法的な構造を明らかにすることができる。構文解析を学ぶことで、自然言語処理で用いられる様々な先人の知恵を学習できる。
この本では以下のような構成となっている。
 1章、はじめに 2章、品詞タグ付けのための手法と、機械学習の基礎的な事項について 3章、句構造解析について 4章、依存構造解析 5章、文法理論、深い構文解析 6章、構文解析の応用例 7章、構文解析ツールの紹介 8章、モデルやアルゴリズムの学習用・評価用データに用いられるツリーバンクの紹介  以下、各章の概要まとめです。
2章：品詞解析と機械学習 品詞解析のためのさまざまな技術の解説し、その基盤となる機械学習の考え方と代表的なモデルを紹介する。
品詞タグ付け：与えられた文章の各単語の品詞を判定し、品詞情報を付与する処理 品詞タガー：品詞タグ付けを行うプログラム ルールベースの手法：shoudの後には動詞がくると決めうちでタグ付けをする手法 素性: 品詞判定の手がかりとして利用する情報</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.if-blog.site/post/nlp/nlp_parse_overview-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.if-blog.site/post/nlp/nlp_parse_overview-1/</guid>
      <description>title=自然言語処理シリーズの構文解析を読む（概要） slug=nlp-parse-overview-1 tags=[nlp,構文解析]
はじめに 自然言語処理シリーズの構文解析を読んでいきます。   全体の概要把握:1時間 中身の細かいとこ：3時間 という感じで読み進めて行こうと思います。
概要 構文解析を用いることで、単語の並びの背後にある文法的な構造を明らかにすることができる。構文解析を学ぶことで、自然言語処理で用いられる様々な先人の知恵を学習できる。
この本では以下のような構成となっている。
 1章、はじめに 2章、品詞タグ付けのための手法と、機械学習の基礎的な事項について 3章、句構造解析について 4章、依存構造解析 5章、文法理論、深い構文解析 6章、構文解析の応用例 7章、構文解析ツールの紹介 8章、モデルやアルゴリズムの学習用・評価用データに用いられるツリーバンクの紹介  以下、各章の概要まとめです。
2章：品詞解析と機械学習 品詞解析のためのさまざまな技術の解説し、その基盤となる機械学習の考え方と代表的なモデルを紹介する。
品詞タグ付け：与えられた文章の各単語の品詞を判定し、品詞情報を付与する処理 品詞タガー：品詞タグ付けを行うプログラム ルールベースの手法：shoudの後には動詞がくると決めうちでタグ付けをする手法 素性: 品詞判定の手がかりとして利用する情報
隠れマルコフモデル 機械学習に基づく品詞タグ付け手法の中で基本的なもの。 単純な計算では、文長に対し計算量が指数関数的に増加する問題がある。
Viterbiアルゴリズム 計算量増加の問題を解決。動的計画法の1種。 アンダーフローの問題がある、この問題に対し、対数をとっても良いが計算が遅くなるというデメリットもある。
最大エントロピーモデル 最大エントロピーモデルは、品詞判定に役立つ手がかりを素性として利用し予測できるアルゴリズムの一種。品詞の前後のつながりを考慮せずに予測するというモデル。 計算コストは少ないが、素性を柔軟に設計できないため精度が低いという問題点がある。 自然言語処理では、実装が簡単なことからSGDがよく用いられる。学習データの数が多い場合には、短時間で最適化を行うことができる。
最大エントロピーマルコフモデル 最大エントロピーモデルに、品詞のつながりを考慮させ正確な予測を行うことできるように改良されたモデル。 先行する単語の品詞に関数情報を素性として利用するできるが、最初にタグ付けを間違えると、その誤りによって別の誤りが引き起こされてしまう問題がある。
条件付き確率場(CRF) 各単語の品詞を個別に予測するのではなく、文全体の品詞列全体を一度に予測しようとするアプローチに基づく代表的な確率モデル。
構造化パーセプトロン CRFでは、登場する品詞列すべてに対し確率を求めるが、もっとも正解である確率の高い品詞列さえ得られれば良いという状況もある。そのような状況では、構造化パーセプトロンが役にたつ。動的計画法を用いて品詞タグ付けを行う。
ビーム探索 構造化パーセプトロンでは動的計画法を用いて品詞タグ付けを行ったが、素性が局所的な場合には、動的計画法が使えない。そこで、非局所的な様々な素性を利用するためによく用いられるのがビーム探索である。似たような手法として、Max Violationがある。
生コーパスを利用した学習 これまでの学習は、コーパスを前提にしたものだった。しかしコーパスの構築には膨大な時間がかかる。与えられた文章のみで学習する手法を、半教師あり学習と呼ぶ。
自己学習 生コーパスを用いる学習に自己学習と呼ばれる方法がある。 これは、CRFや構造化パーセプトロンでは精度向上に効果がないが、隠れマルコフモデルのような生成モデルでは大きな精度向上を得ることができる。これは、生成モデルの場合、EMアルゴリズムの1ステップに対応しているからである。隠れマルコフモデルで自己学習を行う場合、Baum-Welchアルゴリズムを用いる。
3章：句構造解析 構文解析の表現方法の1つである句構造と、それに基づく構文解析の手法について説明する。
句構造 文中の句同士の包含関係を階層的にまとめあげることで、その構造を明らかにする。 適切な句構造を得るための問題を2つに分けると、与えられた文に対して文法上可能な全ての句構造を計算することと、それらの中から最も適切な句構造を選択することとなる。
文脈自由文法 文の句構造を表現するための、最も基本的な文法の一つ。 文脈自由文法のためのボトムアップな構文解析手法の一つであるCKY法と、任意の文脈自由文法を用いてトップダウンに構文解析を行うことが可能なEarly法がある。
確率文脈自由文法(PCFG) 句構造を列挙した上で、最も確からしい句構造を選択する枠組みの1つ
確率文脈自由文法(PCFG)の拡張 PCFGを拡張した、Collins Parserの手法について解説 生成的な確率モデルを注意深く設計することで、正しい構文木にたいして大きな確率がわりあてられるようにする。</description>
    </item>
    
  </channel>
</rss>
